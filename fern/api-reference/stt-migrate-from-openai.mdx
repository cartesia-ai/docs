---
title: "Migrating From OpenAI Whisper to Cartesia Ink"
description: "Use Cartesia's Batch Speech-to-Text API with OpenAI's client libraries"
---

<Info>
**Batch Speech-to-Text**: This documentation covers OpenAI SDK compatibility for Cartesia Ink's batched transcription endpoint.

For real-time transcription, use our [Streaming STT endpoint](/api-reference/stt/stt).
</Info>

Cartesia's Batch Speech-to-Text API provides compatibility with OpenAI's client libraries through the `/audio/transcriptions` endpoint. This allows for easy migration of your use cases to Cartesia's Ink STT.

## Endpoint Options

You have two ways to access Cartesia's Batch STT functionality:

- **Cartesia Native**: `/stt` - Our primary endpoint with full feature support
- **OpenAI Compatible**: `/audio/transcriptions` - OpenAI-compatible endpoint for seamless migration

## OpenAI SDK Usage

For OpenAI SDK users, use the `/audio/transcriptions` endpoint which provides compatibility with OpenAI client libraries:

### Parameter Support

**Supported Parameters**:
- `file` - The audio file to transcribe
- `model` - Use `ink-whisper` for Cartesia's latest model
- `language` - Input audio language (ISO-639-1 format)
- `timestamp_granularities` - Include `["word"]` to get word-level timestamps

**Response Format**: Always returns JSON with transcribed text, duration, language, and optionally word timestamps.

For the complete parameter reference, see our [Batch STT API documentation](/api-reference/stt/transcribe).

### Python Example

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-cartesia-api-key",
    base_url="https://api.cartesia.ai",
    default_headers={"Cartesia-Version": "2025-04-16"}
)

with open("audio.wav", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        file=audio_file,
        model="ink-whisper",
        language="en",
        timestamp_granularities=["word"]
    )
    
print(transcript.text)
```

### Node.js Example

```typescript
import OpenAI from 'openai';
import fs from 'fs';

const client = new OpenAI({
  apiKey: 'your-cartesia-api-key',
  baseURL: 'https://api.cartesia.ai',
  defaultHeaders: {
    'Cartesia-Version': '2025-04-16'
  }
});

const transcription = await client.audio.transcriptions.create({
  file: fs.createReadStream('audio.wav'),
  model: 'ink-whisper',
  language: 'en',
  timestamp_granularities: ['word']
});

console.log(transcription.text);
```

## Direct API Usage

Both endpoints accept identical parameters and return the same JSON response format:

### Cartesia Native Endpoint

```bash
curl -X POST https://api.cartesia.ai/stt \
  -H "X-API-Key: your-cartesia-api-key" \
  -H "Cartesia-Version: 2025-04-16" \
  -F "file=@audio.wav" \
  -F "model=ink-whisper" \
  -F "language=en" \
  -F "timestamp_granularities[]=word"
```

### OpenAI-Compatible Endpoint

```bash
curl -X POST https://api.cartesia.ai/audio/transcriptions \
  -H "X-API-Key: your-cartesia-api-key" \
  -H "Cartesia-Version: 2025-04-16" \
  -F "file=@audio.wav" \
  -F "model=ink-whisper" \
  -F "language=en" \
  -F "timestamp_granularities[]=word"
```

## Migration from OpenAI

To migrate from OpenAI's Whisper API to Cartesia:

1. **Update the base URL**: Change from `https://api.openai.com/v1` to `https://api.cartesia.ai`
2. **Update authentication**: Replace your OpenAI API key with your Cartesia API key
3. **Add version header**: Include `Cartesia-Version: 2025-04-16` in requests
4. **Update model names**: Use `ink-whisper` instead of OpenAI's model names
5. **Keep the same endpoint**: Continue using `/audio/transcriptions`
6. **Avoid unsupported parameters**: Remove `prompt`, `temperature`, and `response_format` parameters
7. **Use timestamp_granularities (Optional)**: Add `timestamp_granularities: ["word"]` to get word-level timestamps

The core functionality remains the same, with JSON responses containing transcribed text and optional word timestamps. 