---
title: Working with WebSockets
subtitle: >-
  Connect to Cartesia over a WebSocket and generate speech from a transcript
  using a given voice and model. The audio is streamed out as Base64-encoded raw
  bytes.
---


<AccordionGroup>
  <Accordion
    title="Example Python Code"
  >
```python
import asyncio
from cartesia import AsyncCartesia
from datetime import datetime
import os
import sys
import wave

async def generate_audio_continuous(client, model_id, output_format, voice_id, transcripts):
    wave_file = wave.open(f'test_gen_continuations_{datetime.now().strftime("%Y%m%d_%H%M%S")}.wav', 'wb')
    wave_file.setnchannels(1)
    wave_file.setsampwidth(2)
    wave_file.setframerate(output_format['sample_rate'])

    # Connect a websocket
    ws = await client.tts.websocket()
    ctx = ws.context()

    for transcript in transcripts:
        await ctx.send(
            model_id=model_id,
            transcript=transcript,
            voice_id=voice_id,
            output_format=output_format,
            continue_=True,
        )

    # Indicate that no more inputs will be sent. Otherwise, the context will close after 5 seconds of inactivity.
    await ctx.no_more_inputs()

    async for output in ctx.receive():
        if "audio" in output:
            buffer = output["audio"]
            wave_file.writeframes(buffer)

    wave_file.close()
    await ws.close()

async def main():
    transcripts = ['Hello, my name is Sonic.', "It's very nice ", "to meet you."]
    voice_id = 'bd9120b6-7761-47a6-a446-77ca49132781' # Tutorial Man

    model_id = "sonic-english"

    output_format = {
        "container": "raw",
        "encoding": "pcm_s16le",
        "sample_rate": 44100,
    }

    # Make sure your API key is set at CARTESIA_API_KEY
    async with AsyncCartesia(api_key=os.environ.get('CARTESIA_API_KEY'), timeout=200) as client:
        # Run the generation
        await generate_audio_continuous(client, model_id, output_format, voice_id, transcripts)

if __name__ == "__main__":
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
    loop.close()
    sys.exit(0)
```
  </Accordion>
</AccordionGroup>


For the best performance, we recommend the following usage pattern:
1. **Set up a WebSocket at start of the conversation** and maintain it throughout the conversation. This incurs a one-time latency cost and optimizes latency for subsequent turns.
2. **One turn should correspond to one context:** Use one context for each turn in the conversation. Contexts maintain prosody between their inputs, so you can send a transcript in multiple parts and receive seamless speech in return.
3. **Buffer the first request transcript** to at least 3 or 4 words for optimizing both latency and prosody.
4. **Split inputs into sentences:** Sending inputs in sentences allows Sonic to generate speech more accurately and with better prosody. Include necessary spaces and punctuation.
5. **Start a new context for interruptions:** If the user interrupts the conversation, start a new context for the agent's response.
6. **Finish a context with an empty transcript:** If you don't know the last transcript in advance, you can send an input with an empty transcript to end the context.

Check out this [Pipecat plugin](https://github.com/pipecat-ai/pipecat/blob/main/src/pipecat/services/cartesia.py) for an excellent example of how to build conversational agents with Sonic.

<Tip>
You can try out WebSockets using `wscat`. If you have Node installed, just run:
</Tip>

```sh In Your Shell
npx wscat -c "wss://api.cartesia.ai/tts/websocket?api_key=<YOUR_API_KEY>&cartesia_version=2024-06-10"
```

`GET /tts/websocket?api_key=<YOUR_API_KEY>&cartesia_version=<API_VERSION>`

Initiate a bidirectional WebSocket connection. The connection supports multiplexing, so you can send multiple requests and receive the corresponding responses in parallel. The connection times out 5 minutes after the last message you send.

## WebSocket Request

Send a JSON-encoded message on the WebSocket. The schema of said message should be identical to the Server-Sent Events request body, except that you must additionally specify a `context_id` field containing a unique identifier for the request. (You can use a UUIDv4 or a [human ID](https://www.npmjs.com/package/human-id).)

```json WebSocket Request
{
  "context_id": "happy-monkeys-fly",
  "model_id": "sonic-english",
  "transcript": "Hello, world! I'\''m generating audio on Cartesia.",
  "duration": 180,
  "voice": {
    "mode": "id",
    "id": "a0e99841-438c-4a64-b679-ae501e7d6091",
    "__experimental_controls": {
      "speed": "normal",
      "emotion": ["positivity:highest", "curiosity"]
    }
  },
  "output_format": {
    "container": "raw",
    "encoding": "pcm_s16le",
    "sample_rate": 8000
  },
  "language": "en",
  "add_timestamps": false
}
```
You may also cancel outgoing requests through the websocket. This will only halt requests that have not begun generating a response yet.

```json WebSocket Request
{
  "context_id": "happy-monkeys-fly",
  "cancel": true,
}
```

## WebSocket Responses

After you send a message body on the WebSocket, the API will respond with a series of JSON chunks with the same schema as the data in Server-Sent Events responses.

```json WebSocket Response
{
  "status_code": 206,
  "done": false,
  "type": "chunk",
  "data": "aSDinaTvuI8gbWludGxpZnk=",
  "step_time": 123,
  "context_id": "happy-monkeys-fly"
}
```

If `add_timestamps` is set to `true`, we will also return messages of the following form in addition to the audio chunks and done message:

```json WebSocket Response
{
  "status_code": 206,
  "done": false,
  "context_id": "happy-monkeys-fly",
  "type": "timestamps",
  "word_timestamps": {
    "words": ["Hello"],
    "start": [0.0],
    "end": [1.0]
  }
}
```

## Input Streaming with Contexts

> In many real time use cases, you don't have your transcripts available upfront—like when you're generating them using an LLM. For these cases, Sonic supports input streaming.

The context IDs you pass to the Cartesia API identify speech contexts. Contexts maintain prosody between their inputs—so you can send a transcript in multiple parts and receive seamless speech in return.

To stream in inputs on a context, just pass a `continue` flag (set to `true`) for every input that you expect will be followed by more inputs. (By default, this flag is set to `false`.)

To finish a context, just set `continue` to `false`. If you do not know the last transcript in advance, you can send an input with an empty transcript and `continue` set to `false`.

<Note>Contexts automatically expire 5 seconds after the last input that was streamed in, and attempting to send another input on the same context ID will implicitly create a new context.</Note>

<ParamField body="continue" type="boolean" default={false}>
    Whether this input may be followed by more inputs.
</ParamField>

### Input Format

1. Inputs on the same context must keep all fields except `transcript`, `continue`, and `duration` the same.
2. Transcripts are concatenated verbatim, so make sure they form a valid transcript when joined together. Make sure to include any spaces between words or punctuations as necessary. For example, in languages with spaces, you should include a space at the end of the preceding transcript, e.g. transcript 1 is `Thanks for coming, ` and transcript 2 is `it was great to see you.`
3. It's important to buffer the first request transcript to at least 3 or 4 words for best performance.

### Example

Let's say you're trying to generate speech for "Hello, Sonic! I'm streaming inputs." You should stream in the following inputs (repeated fields omitted for brevity). Note: all other fields (e.g. `model_id`, `language`) are required and should be passed unchanged between requests with input streaming.

```json Input Streaming
{"transcript": "Hello, Sonic!", "continue": true, "context_id": "happy-monkeys-fly"}
{"transcript": " I'm streaming ", "continue": true, "context_id": "happy-monkeys-fly"}
{"transcript": "inputs.", "continue": false, "context_id": "happy-monkeys-fly"}
```

If you don't know the last transcript in advance, you can send an input with an empty transcript and `continue` set to `false`:

```json Input Streaming
{"transcript": "Hello, Sonic!", "continue": true, "context_id": "happy-monkeys-fly"}
{"transcript": " I'm streaming ", "continue": true, "context_id": "happy-monkeys-fly"}
{"transcript": "inputs.", "continue": true, "context_id": "happy-monkeys-fly"}
{"transcript": "", "continue": false, "context_id": "happy-monkeys-fly"}
```

### Output

You will only receive `done: true` after outputs for the entire context have been returned.

Outputs for a given context will always be in order of the inputs you streamed in. (That is, if you send input A and then input B on a context, you will first receive the chunks corresponding to input A, and then the chunks corresponding to input B.)

## Cancelling Requests
You may also cancel outgoing requests through the websocket.

To cancel a request, send a JSON message with the following structure:

```json WebSocket Request
{
  "context_id": "happy-monkeys-fly",
  "cancel": true
}
```

When you send a cancel request:

1. It will only halt requests that have not begun generating a response yet.
2. Any currently generating request will continue sending responses until completion.

<Note>
The `context_id` in the cancel request should match the `context_id` of the request you want to cancel.
</Note>
