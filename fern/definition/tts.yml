imports:
  voices: ./voices.yml
  embedding: ./embedding.yml

service:
  base-path: /tts
  auth: true
  endpoints:
    bytes:
      path: /bytes
      method: POST
      display-name: Text to Speech (Bytes)
      request: TTSRequest
    sse:
      path: /sse
      method: POST
      display-name: Text to Speech (SSE)
      request: TTSRequest

channel:
  path: /tts/websocket
  display-name: Text to Speech (WebSocket)
  docs: |
    We recommend using this endpoint for real-time applications.

    The WebSocket API is built around _contexts_. When you send a generation request, you pass a context ID. If you want to continue a generation, just pass the same context ID.

    1. Contexts allow you to multiplex multiple generations over a single connection.
    2. Each context maintains prosody between its inputs using a Sonic feature called _continuations_.

    Read the guide on working with contexts to learn more.

    Here's the recommended usage pattern:

    1. **Set up a WebSocket before the first generation.** This gets rid of the latency from connection setup.
    2. **Multiplex generations over a single connection.**
  auth: true
  query-parameters:
    cartesia_version:
      type: string
      docs: |
        You can specify this instead of the `Cartesia-Version` header. This is particularly useful for use in the browser, where WebSockets do not support headers.

        You do not need to specify this if you are passing the header.
    api_key:
      type: string
      docs: |
        You can specify this instead of the `X-API-Key` header. This is particularly useful for use in the browser, where WebSockets do not support headers.

        You do not need to specify this if you are passing the header.
  messages:
    send:
      display-name: "Send"
      origin: client
      body: WebSocketRequest

    receive:
      display-name: "Receive"
      docs: |
        The server will send you back a stream of messages with the same `context_id` as your request.

        The messages can be of type `chunk`, `timestamp`, `error`, or `done`.
      origin: server
      body: WebSocketResponse

types:
  WebSocketBaseResponse:
    properties:
      context_id: string
      status_code: integer
      done: boolean

  WebSocketResponse:
    discriminant: type
    union:
      error: WebSocketErrorResponse
      chunk: WebSocketChunkResponse
      timestamp: WebSocketTimestampResponse
      done: WebSocketDoneResponse

  WebSocketErrorResponse:
    extends: WebSocketBaseResponse
    properties:
      error: string

  WebSocketChunkResponse:
    extends: WebSocketBaseResponse
    properties:
      data: base64
      step_time: double

  WebSocketTimestampResponse:
    extends: WebSocketBaseResponse
    properties:
      word_timestamps: WordTimestamps

  WordTimestamps:
    properties:
      words: list<string>
      start: list<double>
      end: list<double>

  WebSocketDoneResponse:
    extends: WebSocketBaseResponse

  CancelContextRequest:
    properties:
      context_id: string
      cancel: literal<true>

  GenerationRequest:
    extends: TTSRequest
    properties:
      context_id: string
      continue: boolean
      add_timestamps: boolean

  WebSocketRequest:
    discriminated: false
    union:
      - type: GenerationRequest
        docs: |
          Use this to generate speech for a transcript.
      - type: CancelContextRequest
        docs: |
          Use this to cancel a context, so that no more messages are generated for that context.

  TTSRequest:
    properties:
      model_id: string
      transcript: string
      voice: TTSRequestVoiceSpecifier
      language: SupportedLanguage
      output_format: OutputFormat
      duration:
        type: double
        docs: |
          The maximum duration of the audio in seconds. You do not usually need to specify this.

          If the duration is not appropriate for the length of the transcript, the output audio may be truncated.

  SupportedLanguage:
    docs: |
      The language that the given voice should speak the transcript in.

      Options: English (en), French (fr), German (de), Spanish (es), Portuguese (pt), Chinese (zh), Japanese (ja), Hindi (hi), Italian (it), Korean (ko), Dutch (nl), Polish (pl), Russian (ru), Swedish (sv), Turkish (tr).

    enum:
      - en
      - fr
      - de
      - es
      - pt
      - zh
      - ja
      - hi
      - it
      - ko
      - nl
      - pl
      - ru
      - sv
      - tr

  OutputFormat:
    discriminant: container
    union:
      raw: RawOutputFormat
      wav: WAVOutputFormat
      mp3: MP3OutputFormat

  RawOutputFormat:
    properties:
      encoding: RawEncoding
      sample_rate: integer

  RawEncoding:
    enum:
      - pcm_f32le
      - pcm_s16le
      - pcm_mulaw
      - pcm_alaw

  WAVOutputFormat:
    extends: RawOutputFormat

  MP3OutputFormat:
    properties:
      sample_rate: integer
      bit_rate: integer

  TTSRequestVoiceSpecifier:
    discriminant: mode
    union:
      id: TTSRequestIdSpecifier
      embedding: TTSRequestEmbeddingSpecifier
  TTSRequestIdSpecifier:
    properties:
      id: voices.VoiceId
      __experimental_controls: Controls
  TTSRequestEmbeddingSpecifier:
    properties:
      embedding: embedding.Embedding
      __experimental_controls: Controls
  Controls:
    properties:
      speed: Speed
      emotion: Emotion
  Speed:
    docs: |
      Either a number between -1.0 and 1.0 or a natural language description of speed.

      If you specify a number, 0.0 is the default speed, -1.0 is the slowest speed, and 1.0 is the fastest speed.
    discriminated: false
    union:
      - NumericalSpecifier
      - NaturalSpecifier
  NumericalSpecifier:
    type: double
  NaturalSpecifier:
    enum:
      - slowest
      - slow
      - normal
      - fast
      - fastest
  Emotion:
    docs: |
      An array of emotion:level tags.

      Supported emotions are: anger, positivity, surprise, sadness, and curiosity.

      Supported levels are: lowest, low, (omit), high, highest.
    enum:
      - value: anger:lowest
        name: ANGER_LOWEST
      - value: anger:low
        name: ANGER_LOW
      - value: anger
        name: ANGER_NORMAL
      - value: anger:high
        name: ANGER_HIGH
      - value: anger:highest
        name: ANGER_HIGHEST
      - value: positivity:lowest
        name: POSITIVITY_LOWEST
      - value: positivity:low
        name: POSITIVITY_LOW
      - value: positivity
        name: POSITIVITY_NORMAL
      - value: positivity:high
        name: POSITIVITY_HIGH
      - value: positivity:highest
        name: POSITIVITY_HIGHEST
      - value: surprise:lowest
        name: SURPRISE_LOWEST
      - value: surprise:high
        name: SURPRISE_HIGH
      - value: surprise:highest
        name: SURPRISE_HIGHEST
      - value: sadness:lowest
        name: SADNESS_LOWEST
      - value: sadness:low
        name: SADNESS_LOW
      - value: sadness
        name: SADNESS_NORMAL
      - value: curiosity:low
        name: CURIOSITY_LOW
      - value: curiosity
        name: CURIOSITY_NORMAL
      - value: curiosity:high
        name: CURIOSITY_HIGH
      - value: curiosity:highest
        name: CURIOSITY_HIGHEST
